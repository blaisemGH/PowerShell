# partitioning.merge specifies that the partitioning phase of a process can execute master schema updates specified in the temp schema
#   to tackle performance problems for updating the master schema within a process
#   must be activated per default for new X1 Storage component, see prerequisites in Abacus360 Wiki for X1 Storage Configuration
# default: true
partitioning.merge = true

# partitioning.merge.useInlist specifies whether an In-List or a nested select is used to determine the records in the master schema that potentially
# need updating (only used if partitioning.merge=true)
# default: true
# partitioning.merge.useInlist=


# don't create an edit partition when partitioning.merge is true, variable is used in some MPE processes
# where all updates on the master schema are done via partition.merge mechanism, if enabled
# false: edit partition will not be created
# true: edit partition will still be created
# default: true
# partitioning.merge.edit=true

# partitioning.deletedRecords specifies that the partitioning phase of a process copies deleted records (change_status=5) into the master schema.
# Please don't change this without support. With setting this parameter to false, records will not be visible again, when partition is deleted and workspaceDeletionLogic = 0 
# default: true
# partitioning.deletedRecords=false

# Activate if you want to use Abacus 360 7.x Embedded Only
# When activated, advanced 7.x features such as DAAL, Spark and SQLX will not be used and do not have to be configured
# Default: false
# embeddedOnly=true

# The connect identifier for the database (usually resolved via tnsnames.ora)
# These are the only relevant parameters for the SQL*Loader call, and the only db.set* parameters not relevant for JDBC connections.
db.setSID = ABACUS_PDB.gke
# Set db.setEasyConnect to use Oracle EasyConnect instead of tnsnames.ora lookup using db.setSID for calls to SQL*Loader.
# Format: <host>:<port>/<service>
#db.setEasyConnect=localhost:1521/ORCL
db.setEasyConnect = oracle-1915-svc:6021/ABACUS_PDB.gke


######## Parameters relevant for JDBC connections ########

# the Oracle database driver type (standard: thin)
db.setDriverType = thin

# the application database user for ABACUS
db.setAppUser = 

# the application database user's password
db.setAppUserPwd = 

# the user of the master database schema
db.setUser = abacus_master

# the user of the vdal database schema
db.setVdalUser = abacus_vdal

# the password of the master database schema
db.setPassword = abacus_master

# the value of the password.bat/password.sh encrypted password, if it was encrypted
# crypted.db.password=encryption_string

# the Oracle database port number
db.setPortNumber = 6021

# the Oracle server name
db.setServerName = oracle-1915-svc

# the Oracle database name, this is usually the SID
db.setDatabaseName = ABACUS_PDB.gke

# the value of this property is used as the default batch size when using Oracle executes a statement with multiple bind variables.
# db.defaultExecuteBatch=1000

# the Oracle database service name (setting this will make the JDBC driver ignore the db.setDatabaseName setting)
# Several different service names can be specified (which only really makes sense in a RAC installation):
# For the ABACUS services, and as default for the remaining service name parameters:
# db.setServiceName
# For connections from the web server side:
# db.setServiceName.gui
# For MPE processing, unless a service name for a specific temp schema is specified:
# db.setServiceName.temp
# For a specific temp schema (temp schema name must be lower case here):
# db.setServiceName.temp.<TEMP_SCHEMA>
# For partitioning operations:
# db.setServiceName.partitioning

# Tell the JDBC driver to use a different batch flushing behaviour by setting AccumulateBatchResult connection property.
# To use only in cases where this behaviour would influence the performance of Additive Loading severely.
# Default is true.
# db.setAccumulateBatchResult=false

# General Java-Bean Setters for JDBC Datasource Methods can be set by
# any db.set* Method. Setting the property will call the corresponding datasource setter method and assign to it the value of the property.
# Example: "db.setURL=jdbc:oracle:thin:@localhost:1521:orcl" will call the method setURL("jdbc:oracle:thin:@localhost:1521:orcl") for the
# datasources used in the application.      

# minimum connections stored in the pool. New connection will be created if the number of connections in the pool is below this number
pool.min = 25

# maximum number of connections. If the number of connections given back to the pool is higher than this value, the connections will be removed
pool.max = 100

# the number of milliseconds that limits the life time of a connection within the pool
pool.maxLifeTime = 1800000

# the time between two runs of the pool maintenance thread in milliseconds
pool.maintainTime = 30000

# All pool.* properties will set pool properties for the Oracle Pool, such as defined by
# oracle.jdbc.pool.OracleDataSource. 

# the value of this property is used as the default number of rows to prefetch for connection pooling
OnlineRowPrefetch = 10

######## End of parameters relevant for JDBC connections ########

# defines whether 4-eyes-concepts are used
# allowed values enabled/disabled
four_eyes = disabled

# The function "Freischalten" is possible only if the actual owner of the EDIT partition is not equal to the creator of the EDIT partition;
# allowed values: enabled (default) or disabled.
# This parameter can only be used if the parameter four_eyes is set to enabled.
# non_hierarchic_four_eyes=disabled

# defines whether the Oracle insert --+ append should be used or not during XBA
# to avoid "No more data to read from socket" on some databases (esp. 10.2.0.3)
# default: true
# if set to false, append is not used during the allocation (but slows down allocation)
xba.useAppend = true

# defines how to store input files of a process
#   YES - store them in both the log directory and a zip archive
#   NOSTORE - store them only in a zip archive
#   NOZIP - store them only in the log directory
#   NO - don't store them at all
# default is YES
storeInputFiles = NO

# defines how to store output files of a process
#   YES - store them in both the log directory and a zip archive
#   NOSTORE - store them only in a zip archive
#   NOZIP - store them only in the log directory
# default is YES
#storeOutputFiles=YES

# defines how to store the xml or fixformat loader dat and ctl files in order to backup them for auditing reasons
#   YES - will store the dat and ctl files according to the storeOutputFiles configuration
#   NO - don't store them at all
# default is NO
#storeLoaderFiles=NO

# defines if the xml or fixformat loader dat and ctl files should be deleted immediately at the end each loading thread
# this can be useful if there are many big dat files (e.g. during archive loading)
# default is NO
# YES will delete the files immediately at the end of each loading thread (except storeLoaderFiles is set to YES)
#deleteLoaderFilesImmediately=NO

# set to YES to enable logging of the jdbc operations within the ABACUS services and MPE processes
logDataSource = NO

# uncomment and set to YES to enable logging of the jdbc operations within the MPE processes
# If not specified or empty, 'logDataSource' will be used, if filled.
# logMPEDataSource=NO

# uncomment and set to YES to enable logging of the jdbc operations within the ABACUS services
# If not specified or empty, 'logDataSource' will be used, if filled.
# logServicesDataSource=NO

# set to YES to enable logging of the jdbc operations within the gwt gui
# If not specified or empty, 'logGUIDataSource' will be set to NO
logGUIDataSource = NO

# set to YES to enable logging of the jdbc operations within the gwt gui via JMS Logger
jmsLogGUIDataSource = NO

# log queries only if duration exceeds x ms. Set the duration in ms. Default: deactivated (empty) = no restriction
logDataSourceDuration = 

# log queries in MPE processes only if duration exceeds x ms. Set the duration in ms. Default: deactivated (empty) = no restriction
# If deactivated (empty), then 'logDataSourceDuration' will be used, if activated.
# logMPEDataSourceDuration=

# log queries in ABACUS services only if duration exceeds x ms. Set the duration in ms. Default: deactivated (empty) = no restriction
# If deactivated (empty), then 'logDataSourceDuration' will be used, if activated.
# logServicesDataSourceDuration=

# log queries in the gwt gui only if duration exceeds x ms. Set the duration in ms. Default: deactivated (empty) = no restriction
# If deactivated (empty), then 'logDataSourceDuration' will be used, if activated.
# logGUIDataSourceDuration=

# defines if edit partition will be automatically
# created when a base partition for a new repdate
# is created. Can only be used when four_eyes=disabled.
auto_edit = disabled

# defines the strategy class for mapping logical on physical partitions
#
# com.bearingpoint.davinci.database.partition.strategy.OnePerDayStrategy
# for all logical partitions of a certain day and cluster, one physical partition is created.
# optimized for fast online respone time
#
# com.bearingpoint.davinci.database.partition.strategy.OnePerEditStrategy
# every logical calc partition (except "small" ones) has a physical partition,
# all edit partitions of one day and cluster are mapped to one physical partition.
# trade-off between partitioning time and online response time
#
# com.bearingpoint.davinci.database.partition.strategy.NoPartitionStrategy
# no partitioning. Can be used with non-enterprise versions of Oracle

partition.strategy = com.bearingpoint.davinci.database.partition.strategy.OnePerEditStrategy

# define if the partition strategy is using multitenancy
# default: false
# partition.multitenant=true

# Definition of tablespace manager for physical partitioning. A user can implement
# the interface TableSpaceManager in order to provide a tablespacename for each 
# partitioned table, which is filled during a mpe process. The default implementation returns an empty 
# tablespace name and the behavior is that the default tablespace of the target schema is used
newpartition.tableSpaceManager = com.bearingpoint.davinci.database.tablespace.DefaultTablespaceManager

# Definition of the partition range. Default is set to 1000, which means, that a max of 1000 logical partitions are expected per cluster.
# partition.range=1000

# enables/disables Oracle enterprise hash partitioning, bitmap indexes and index compress option
# set "no" to work with standard edition
# allowed values yes/no
# default value is yes
# oracleEP=no

# number of times that a rebuild of an index partition is retried if it failed
# default is 2
indexes.build.retry.count = 2
# time in milliseconds before a rebuild of an index partition is retried after it failed
# default is 1000
indexes.build.retry.wait = 1000

# defines if an existing compression of the master schema should be respected
# (setting this to true will currently drop bitmap indexes before EXCHANGE PARTITION, as this will not work if the partition is compressed)
# for Oracle Enterprise Edition the recommended value is true (use Oracle Basic Compression)
# which can save up to 50 percent of database storage in the Oracle tablespace for the partitioned tables and indexes in master schema
# default is true
compression.isUsed = true

# uncomment the following entry if ORA-00600 with [15598] occurs during updates in VDAL views
# updateMasterHint=opt_param('hash_join_enabled','false')

# if consistency check and loader are started separately this hint might be useful for performance reasons.
# if the following line is uncommented, the update of field 'status' in recs_type_930 is directly done in 
# master schema. The vdal schema is omitted.
# updateMasterConsHint=VDAL OFF

# Sets the percentage for gathering table statistics with meta_ddl.analyze_table on X# tables and added partitions.
# NULL - for gathering table statistics with DBMS_STATS.AUTO_SAMPLE_SIZE.
# Default: NULL
# partitionStatsSamplePercent=1

# If the global statistics process does not finish, uncomment the following parameter.
# The percentage may be modified, a higher value will be more precise but the process will run longer.
# Default: automatically defined by Oracle
# completeStatsSamplePercent=1

# The parallel degree used within the global statistics can be adapted with the following parameter.
# Default: twice the parallelDegree of jcal.properties.
# completeStatsParallelDegree=2

# Percentage parameter for mpeDBStatisticsEdit, i.e. DB statistics for the edit schema.
# The percentage may be modified, a higher value will be more precise but the process will run longer.
# Default: automatically defined by Oracle
# editStatsSamplePercent=10

# The parallel degree used within the statistics for the edit schema can be adapted with the following parameter.
# Default: twice the parallelDegree of jcal.properties.
# editStatsParallelDegree=2

# The parallel degree used for filling temporary tables during partitioning can be adapted with the following parameter.
# Default: parallelDegree of jcal.properties.
# parallelDegreePartitioning=2

# The parallel degree of threads used within the partitioning, specifying the number of tables that can be
# treated at the same time by the partitioning component.
# Default: parallelDegree of jcal.properties.
# parallelDegreeThreads=2

# Set a detailed parallel degree of threads within partitioning for small and/or large tables
# parallelDegreeThreadsSmallTables=
# parallelDegreeThreadsLargeTables=

# Define the layers to be used by Abacus (here including the custom layer)
layers = engine reporting-engine xbrl core awv corep finrep-core sbp assetencumbrance almm ssm_le resrep mrel res-plans de ezbstat bsk crd4-li lima eaeg banking banking-corep anacredit statistics compare migration riva dqi autopilot custom

# Define the layer to be used by Abacus to write user settings (it replaces the default $ABACUS_HOME/custom/properties/<username>).
# writeLayer=
writeLayer = /opt/abacus/custom/usersettings


# Different layer configurations can be added by layers.*, where layers.* must be a subset of the layers parameter.
# The name "layers.default" is NOT allowed.
# Example:
# layers=engine xbrl core corep de ezbstat custom
# layers.old = engine core de ezbstat custom 

# Define layer configuration to display as preselected value in the login screen
# activation.preselect = old

#Parameters starting with sourceDB.* are used to link to another Abacus System.
#sourceDB.PRODUKTION=produktion_master

# The number of times a failed query for creating a new physical partition on an existing
# repdate/cluster with OnePerEditStrategy (ALTER TABLE SPLIT) will be executed again, if it
# failed with ORA-00054 (resource busy and acquire with NOWAIT specified).
# default: 1
partitioning.splitretry = 1

# Time (in ms) the system will wait in order to retry a failed query for creating a new
# physical partition on an existing repdate/cluster with OnePerEditStrategy, if it
# failed with ORA-00054 (resource busy and acquire with NOWAIT specified).
# default: 1000
partitioning.splitretrytime = 1000

# Bypass the VDAL triggers when saving or applying changes to the reporting sets (Formularsaetze).
# Values true/false, default true. A value of false will perform much better but disables change logging for the reporting sets.
excluded_reports.useVdal = true

# The maximum size for plot_fk "in-string" constant lists. If the size is exceeded, MPE will change the "in-string" parameter in
# sub-queries, querying generated PF# tables.
# In the Cache Loader, a bind variable with the collection of plot_fk values will be used instead of PF# tables if the number
# of partition IDs exceeds the threshold.
# The default value is 1000
# plot_fk_string_max_size=1000

# The caching size for Cube Pools. Default is set to 20. It makes sense to set it about twice the number of concurrent users.
# But if db.cubePoolUseVdalDataSource is set to true and you experience too big a usage of DB connections by ABACUS, you may
# need to set it lower than this.
db.cubePoolCacheSize = 20

# Specify if the cube pool should use datasources which cache their connections. May improve GUI performance well.
db.cubePoolUseVdalDataSource = true

# the number of milliseconds that limits the life time of a connection within the pool
cubePoolVdalDataSource.maxLifeTime = 1800000

# the time between two runs of the pool maintenance thread in milliseconds
cubePoolVdalDataSource.maintainTime = 30000

# The caching size for the underlying pool common to all Cubes. This determines reusage of old connections among all users.
# Default is set to 10.
# If caching is undesired, a value of 0 can be set.
# db.vdalgui.poolsize=10

# The number of milliseconds that limits the life time of a connection within the common pool underlying all Cubes
# Defaults to 600000 ms (10 min)
# db.vdalgui.maxLifeTime=600000

# use pivoted tables (affects the xml loader which verticalizes delivered data into a pivot structure, subsequent processes rely
# on that pivoted structure if this parameter is set to true
# Since ENG R1.8.0.00 the pivot structure of input data (recs_type_930_base and recs_type_930_v) is mandatory and value true should be set
db.usePivotTables = true

# CSV list of fields to exclude from pivot table creation ( recs_type_930_calc )
# db.usePivotTables.excludeFields=

# If set to a value greater than 1, the base table will be cut into slices and each slice will be pivoted seperately, one after one.
# This is to avoid performance problems during pivoting. The corresponding value table will also be cut into slices,
# unless deactivated with the following property (db.usePivotTableSlicesForValuesToo).
# Since this functionality uses table partitioning, it can only be used with Oracle's Enterprise Edition.
# Default: 1
db.usePivotTableSlices = 1

# If slicing of the base table is enabled (i.e. db.usePivotTableSlices > 1, see above) this property can be used to disable
# the usage of a hash partitioned key table that contains only the hash key field (C200). A hash partitioned temporary table
# containing all fields will be used instead.
# Default: true 
db.usePivotTableKeyHashTable = true

# If slicing of the base table is enabled (i.e. db.usePivotTableSlices > 1, see above) this property can be used to switch off
# slicing for the corresponding value table. Creating the slices might be slower than the performance gain when joining with
# the slices of the base table.
# Default: true 
db.usePivotTableSlicesForValuesToo = true

# Some parameters for fine-tuning the performance of pivoting. Each of these will be used explicitly in an Oracle hint,
# if specified and greater than 0. The precise effect needs a deeper insight into the class that uses them and may vary.
# They can be tested, though, using the process "tools -> Pivot-Test".
# Default for each one: -1
db.usePivotTableSelectSliceParallelDegree = -1
db.usePivotTableSelectPivotInnerParallelDegree = -1
db.usePivotTableSelectPivotOuterBaseParallelDegree = -1
db.usePivotTableSelectPivotOuterVParallelDegree = -1
db.usePivotTableSelectAppendSliceParallelDegree = -1


# specifies whether to check at services startup if required versions are installed
# 	if true and required versions are not all installed, the startup is aborted
# 	if false and required versions are not all installed, the missing versions are only logged 
versioncheck.startup = true

# Specifies the parallel degree that is applied to some of the queries used for the reporting status monitor.
# e.g. when refreshing the reporting status monitor with the new data from the monitoring table
# Default: 1
# reportingStatusMonitorParallelDegree = 1


# Enable Oracle 12 GATHER AUTO feature in DMB_STATS package. Set true with Oracle 12 upwards only!
# GATHER_AUTO gathers all necessary statistics automatically.Oracle implicitly determines which objects
# need new statistics.
db.gatherStatsOptional = false

# Specifies a number of records modified in the edit partition by vertical mass update. After this many or more records
# have been modified, statistics will have to be gathered on the partition.
# Values of 0 or 1 mean no threshold.
# Recommended: db.gatherStatsOptional is true, then set this to 0.
#db.editPartAnalyzeThreshold=1000

# Specifies if the optional materialize for the sub query with new_vals as (...) in Java Native Class UnpivotTable should be used or not
# Default: true (materialize hint is used)
db.unpivotTableMaterializeWithNew_vals = true

# Specifies if parallel hints (with mpe.parallelDegreePivotTables if it is defined) for the sub queries in Java Native Class UnpivotTable should be used or not
# Default: true (parallel hints are used)
db.unpivotTableUseParallelHints = true

# Specifies the maximum number of connections in the "vdal" pool.
# 	New connections are opened only if the maximum number has not been reached.
#	The default is a maximum of 3 connections.
db.vdalMaxConnections = 3
# Specifies the maximum life time (in milliseconds) of a connection in the "vdal" pool.
#   After the specified amount of time spent in the pool, a connection is automatically closed
#	The default is a maximum life time of 10 s (10000 ms). 
db.vdalMaxLifeTime = 10000

# Specifies if the application may use the DBMS_SCHEDULER package. Defaults to true.
# db.useDbmsScheduler=false

# defines whether parallel dml should be enabled or not for the the single SQL queries in XBA
# this could improve performance e.g. of process step XBAPure in ADV MPE process mpeLCRNSFR_ITS for a very high data volume of recs_type_30_crd4li
# if set to true, alter session enable parallel dml is activated for the Oracle sessions of XBA (in Java classes Allocator2 and AllocationExecutor)
# remark: for XBA with many reporting modules in parallel (e.g. XBAPure in mpeAll for "XBA EZBStatistik" and "XBA EZBStatistik 2014") the parameter value is temporarily set to false to avoid to high parallelism 
# default: false
xba.enableParallel = false

# The parallel degree used for allocation of reports (calculating allocated positions with single insert ... select statements) can be adapted with the following parameter.
# this could improve performance e.g. of process step XBAPure in ADV MPE process mpeLCRNSFR_ITS for a very high data volume of recs_type_30_crd4li
# the parameter value is usually set in combination with xba.enableParallel=true and should not be set too high (e.g. half the value of parallelDegree of jcal.properties)
# remark: for XBA with many reporting modules in parallel (e.g. XBAPure in mpeAll for "XBA EZBStatistik" and "XBA EZBStatistik 2014") the parameter value is temporarily set to 1 to avoid to high parallelism 
# default: 1
# xba.parallelDegree=1

# The parallel degree used for allocation of reports (copy calculated allocated positions from global temporary allocation table to final allocation table) can be adapted with the following parameter.
# this could improve performance e.g. of process step XBAPure in ADV MPE process mpeLCRNSFR_ITS for a very high data volume of recs_type_30_crd4li
# the parameter value is usually set in combination with xba.enableParallel=true and should not be set too high
# remark: this parameter is only relevant if xba.useAppend=true (global temporary allocation table is used for storing the allocated positions during allocation phase)
# default: parallelDegree (jcal.properties)
# xba.parallelDegreeCopy=2

# defines for allocation of reports if it should be checked before copy of calculated allocated positions from global temporary allocation table to final allocation table if any records exist in global temporary allocation table
# if there are no records in global temporary allocation table the copy to final allocation table is skipped 
# this could improve performance e.g. of process step XBAPure in ADV MPE process mpeLCRNSFR_ITS if there are many insert ... select ... statements which don't copy any records from lobal temporary allocation table to final allocation table
# remark: this parameter is only relevant if xba.useAppend=true (global temporary allocation table is used for storing the allocated positions during allocation phase)
# default: false
xba.checkIfRecordsExistBeforeCopy = false

# defines whether new with ... logic should be enabled or not for the the single SQL queries in XBA
# this could improve performance e.g. of process step xbaCoRep in ADV MPE process mpeBasel3
# if set to true, the new with ... logic is activated and because of this bitmap indexes are used more often because of sub query factoring
# default: false
xba.enableWithForAllocationQuery = false

# The maximum count of connections (parallel allocation threads) used for allocation of reports can be adapted with the following parameter.
# fine-tuning with this parameter (higher value than parallelDegree) could improve performance of allocation phase (e.g. XBAPure in mpeAll) if there are enough parallel resources available
# default: parallelDegree (jcal.properties)
# xba.maxConnections=2

# Defines if the WorkspaceConnection and VDALConnection will produce bind PreparedStatement's.
# If enabled and "useExplicitPlotFkRestriction" is also enabled, then all the PLOT_FK's in the restriction list/s will be set as deferred bounded values.
# Increase in performance by using PreparedStatement.
# Default: false.
vdal.plotfk.produceBindStatements = false

# Defines if the WorkspaceConnection and VDALConnection will produce bind PreparedStatement's.
# If enabled and "useExplicitPlotFkRestriction" is also enabled, then all the PLOT_FK's in the restriction list/s will be set as deferred bounded NUMERIC TYPE TABLE values.
# If this is enabled, then it will override "vdal.plotfk.produceBindStatements".
# Increase in performance for large number of PLOT_FK's (over 1000).
# Default: false.
vdal.plotfk.produceTypeTableBindStatements = false

# Specifies if an optional Oracle hint is used for searching invalid f001 in a table during partitioning phase
# Default: no_gather_optimizer_statistics first_rows(1)
# This may improve the duration during partitioning phase e.g. for vertical table recs_type_930_v when the count of records of this table is very high
# Remark: this parameter is only relevant if parameter sec.useUserGroups=true is set in security.properties
copyPartitionsSearchInvalidF001Hint = no_gather_optimizer_statistics first_rows(1)

# The number of requests to the DBManagementService regarding partition adding/deleting which are allowed to be treated in parallel.
# Defaults to 1. Affects performance of parallel MPE processing.
# Currently only the exchangePartitions() call is eligible for such parallelizations - deleting is always exclusive.
# DBManagementService.parallelDegreeThreadsAddDeletePartitions=

# Sleep time for threads waiting on critical actions, in case DBManagementService.parallelDegreeThreadsAddDeletePartitions is greater than 1.
# Defaults to 1000.
# DBManagementService.waitCriticalActionSleepTimeMs=

# Sleep time for threads waiting to enter a state settings of the DBManagementService states.
# Defaults to 1000.
# DBManagementService.waitStateSleepTimeMs=

# Threshold of DBManagementService request waiting times in milliseconds from which on to log these on INFO level.
# Defaults to 10000 (10 seconds).
# DBManagementService.waitTimeLoggingThresholdMs=

# The batch and commit size are used within the Writer threads. A higher number might improve performance, as it reduces the number of commands set to the database.
# On the other hand, a higher number will result in a higher memory consumption of the worker and a too high number can result in Oracle Exceptions
db.maxJdbcWriterEngineBatchSize = 1000

#The batch and commit size are used within the Writer threads. A higher number might improve performance, as it reduces the number of commands set to the database.
#On the other hand, a higher number will result in a higher memory consumption of the worker and a too high number can result in Oracle Exceptions.
#Only change the default value from 1 after consultation with Regnology. Using a higher value than 1 is forbidden if useMultipleTableAppend=true is set
db.maxJdbcWriterEngineThreads = 1

#The batch and commit size are used within the Writer threads. A higher number might improve performance, as it reduces the number of commands set to the database.
#On the other hand, a higher number will result in a higher memory consumption of the worker and a too high number can result in Oracle Exceptions.
db.useAppendHintForWriter = true

#If set to true, the Writer instances within the worker node will use a dedicated table per thread.
#Setting this option to true only makes sense if useAppendHintForWriter has been set to true.
db.useMultipleTableAppend = true

# Configure hint for queries used in creating indexes on tables during partitioning operations.
# createIndexesLikeHint=

# Degree of parallelism for small tables in partitioning phase - number of threads that execute the relevant DB operations. 
# Obsoletes parameter parallelDegreeIndex from 5.15.2 on. If not given, the following properties are evaluated and taken by first match:
# paralleldegreeSmallTables -> parallelDegreePartitioning -> parallelDegree -> default: 1 
# parallelDegreeSmallTables=1

# Degree of parallelism for large tables in partitioning phase - number of threads that execute the relevant DB operations. 
# Obsoletes parameter parallelDegreeIndex from 5.15.2 on. If not given, the following properties are evaluated and taken by first match:
# parallelDegreeLargeTables -> parallelDegreePartitioning -> parallelDegree -> default: 1 
# parallelDegreeLargeTables=1 

# Time to wait in seconds between refreshs of the ping signal for check of multiple services on same database instance
# instancePingIntervalSeconds=20

# During startup of a service instance some factor is applied to instancePingIntervalSeconds to determine startup timeout  
# instancePingStretchFactor=1.5

# During certain operations, the application issues calls in the database to gather statistics for table partitions.
# These operations can be customized as follows.
#
# Flag to decide whether each statistics gathering call is scheduled independently (old implementation) or calls are gathered in batches
# to be executed together periodically (new implementation).
# Possible values:
#    true - calls are batched and scheduled periodically (condition: db.useDbmsScheduler is active)
#    false - calls are scheduled individually as they are issued
# Default value: true
# db.partitionStats.batched=false
#
# Time between subsequent batches
# Unit: seconds
# Default: 30
# db.partitionStats.batch.intervalSeconds=30
#
# Number of requests inside a batch
# Default: 1000
# db.partitionStats.batch.size=1000

# Specifies the maximum number of entity data missing in data cache which can be reloaded from the database.
# If the number of missing entity data is larger than the limit, a warning is logged [entity name, #missing entity data] and a corresponding exception is thrown.
# Refer to the warning to enrich the entity list of the corresponding component in MPE x1CacheLoader, or to increase the limit accordingly if the DB can handle the load.
# Default: 1000.
db.reloadLimit = 1000

# The granting of rights to/from the archive schema that takes place during archive export and import should be on/off switchable because some environments do not allow granting of rights during runtime.
# The archive.grantRights parameter defaults to true.
# archive.grantRights=true

# Deactivate the order by fields which are defined in partitions.xml for specific tables during partitioning phase.
# The list of table names can be specified with the following parameter.
# This list is comma-separated. The case of table names is ignored during the check if the name of the table to be partitioned is included in the list of table names.
# Example: If the order by fields are activated for table recs_type_5 this could speed up search queries e.g. in loan manager as records are pre-ordered by p019
# but using order by fields during partitioning phase will increase runtime and needs more TEMP tablespace for execution of the insert statement.
# Default: empty (there are no tables are specified for which the the order by fields are deactivated during partitioning phase)
# partitioning.deactivate.orderbyfields.tables=

# Deactivate the order by fields which are defined in partitions.xml for all tables during partitioning phase.
# If the parameter partitioning.deactivate.orderbyfields.all.tables=true is set then the parameter partitioning.deactivate.orderbyfields.tables=<comma-separated list of table names> is ignored.
# Default: false (the order by fields are activated for all tables during partitioning phase)
# partitioning.deactivate.orderbyfields.all.tables=false

# Use SPLIT PARTITION ... ONLINE feature instead of SPLIT PARTITION ... UPDATE GLOBAL INDEXES to avoid DML locks during partitioning phase.
# This feature was added in Oracle 12.2 and should not be activated in Oracle 19 as SPLIT PARTITION ... ONLINE operation might fail from time to time during partitioning phase and
# causes inconsistencies in the Oracle database which require each time an execution of a workaround script that was provided by Oracle.
# See: Bug 29818474 : Logical corruption during SPLIT PARTITION in https://www.wiki.reg.tech/display/GEN/Oracle+19+Recommendations
# If this new feature is not activated then ORA-04021: timeout occurred while waiting to lock object errors might occur during partitioning phase.
# Default: true
# partitioning.split.online=false

# In some specific Oracle installations, Oracle Dictionary can show references to another user SYNONYMS based on PLSQL procedures and functions
# which can cause an error in some MPE executions (e.g. gather_stats) and must be explicitly excluded from the code. This additional check might lead to
# performance decrease based on database volume.
# Default value is true - synonyms are explicitly excluded from the code.
# db.excludePLSQLsynonymsFromVDALDataSource=false

######## Configure JDBC connections to Hive via DAAL ########
# Without SSL:
# db.hive.url=jdbc:hive2://localhost:10000
# With SSL:
# db.hive.url=jdbc:hive2://localhost:10000/;ssl=true
# When SSL is enabled then use below db.hive.url and make sure to set sec.client.keystore.url and crypted.clientStorePassword in security.properties
# When SSL is true i.e. wildfly.use.https=1 in wildfly.properties, below property must be set, connection URL to hive will also need client store url and password to establish secure connection
# Full URL will be created using 3 properties db.hive.url, sec.client.keystore.url and crypted.clientStorePassword
db.hive.url = jdbc:hive2://localhost:10000

# Defines how Select query for Vertical tables is created
# Parameter verticalTablesWITHSelectClause need to be filled with Regular expression defining which tables it will affect
# if verticalTablesWITHSelectClause is set then for each matching table a separate sub select using WITH clause is created.
# Together with this parameter some additional conditions are internally checked in order to use this type of selects
# This class is when WITH type of select condition is switched on and when where condition given to SQL
# is possible to be used in this way.
#
# Excluded from using this class are conditions where
# - for at least one field in where clase there is defined default value in the Metamodel
# - any negative condition like '<>', not like, not in, not between, not null
# Currently this functionallity is supported only for Anacredit datamart tables, so the regular expression should
# Example: ^DM_AC_[A-Z]+(_H|_M)$ is to be set to switch this rule for all tables starting with DM_AC_ and ending with _H or _M
#verticalTablesWITHSelectClause=^DM_AC_[A-Z]+(_H|_M)$

# Defines how Parallel Degree of Sub Select query when verticalTablesWITHSelectClause is selected.
# Default values 1 means that non parallel executions of GUI queries
parallelDegreeSQLVerticalStatementBuilder = 1

# Replace all append hints by enable_parllel_dml hints or add enable_parllel_dml hints for all insert, update and merge into sql statements.
# This automatical conversion of sql queries can be activated for performance reasons and affects all sql queries of MPE process using MPEDataSource and MPEConnection and
# the insert sql queries which are executed by the PartitionManager during partitioning phase of MPE processes.
# Default: false
# useEnableParallelDmlInsteadOfAppend=true
useEnableParallelDmlInsteadOfAppend = true
db.setServiceName = ABACUS_PDB.gke
db.setURL = jdbc:oracle:thin:@//oracle-1915-svc:6021/ABACUS_PDB.gke
db.maxJdbcWriterEngineBatchSize\= = 1000
db.setTTUser = ABACUS_ARCHIVE
db.setTTPassword = ABACUS_ARCHIVE
