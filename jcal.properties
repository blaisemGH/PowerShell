# the parameter ModelCommitEvery should be set to a positive number
# the number of (written) data records in a PreparedStatement after which a executeBatch is called
ModelCommitEvery = 1000

# Uncomment the parameter debugBatchUpdateException=true if your MPE process
# failed with a java.sql.BatchUpdateException in order to log more debugging
# info about that. The parameter ModelCommitEvery=1 should be set together
# with this to facilitate the analysis. 
#debugBatchUpdateException=true

# the value of this property is used as the default batch size when using Oracle style batching. 
# !!! This value is currently deprecated 
# DefaultExecuteBatch=1000

# the value of this property is used as the default number of rows to prefetch
DefaultRowPrefetch = 50

# indexOptions for TEMP schema index building. The parallel degree should be set equivalent to the parameter parallelDegree or buildDB.parallelDegree,
# the tablespace clause should specify the same tablespace as in parameter indxTBS or, if present, stagingTBS.
indexOptions = parallel (degree 8) nologging tablespace ABACUS_PDB_STAGING

# the java options are used i.e. for setting the initial and maximal java heap size (see java -? or java -X)
# -Xms = maximum java heap size
# -Xms (inital java heap size) should be set <= to the -Xmx value
# -Xmn (heap size for young generation) should be set to about 40-45% of the -Xmx value
# For Solaris 64-bit add -d64 -server
JavaOptions = -XX:+IgnoreUnrecognizedVMOptions -DA360=abacus360 -server -d64 -XX:+DisableExplicitGC -Xms512m -Xmx12G -Djava.awt.headless=true -Dfile.encoding=ISO-8859-1 -Djava.security.egd=file:/dev/urandom -Djavax.xml.parsers.SAXParserFactory=org.apache.xerces.jaxp.SAXParserFactoryImpl -verbose:gc  -Djava.io.tmpdir=/opt/abacus/temp/

# Another set of java options may be defined for processes that require significantly higher amounts of memory.
# If this is kept commented out, 'JavaOptions' will be used instead.
# JavaOptions2=-XX:+DisableExplicitGC -Xms256m -Xmx6G -Djava.awt.headless=true -Dfile.encoding=ISO-8859-1 -Djavax.xml.parsers.SAXParserFactory=org.apache.xerces.jaxp.SAXParserFactoryImpl
JavaOptions2 = -XX:+IgnoreUnrecognizedVMOptions -DA360=abacus360 -server -d64 -XX:+UseCompressedOops -Xms1G -Xmx12G -Djava.awt.headless=true -Dfile.encoding=ISO-8859-1 -Djava.security.egd=file:/dev/urandom -Djavax.xml.parsers.SAXParserFactory=org.apache.xerces.jaxp.SAXParserFactoryImpl -verbose:gc  -Djava.io.tmpdir=/opt/abacus/temp/


# the parallel degree of the application server should be less than or equal to the number of available CPUs
parallelDegree = 8

# the record buffer size used by the xml data loader
RecordBufferSize = 300000

# the table buffer size used by the xml data loader
TableBufferSize = 1000

# the parameter to parse the log file generated by the xml data loader for looking up successfully loaded records
LogParseSuccess = ([0-9]*) (((Zeile|Zeilen) erfolgreich geladen.)|((Row|Rows) successfully loaded.))

# the parameter to parse the log file generated by the xml data loader for looking up erroneous loaded records
LogParseFail = ([0-9]*) (((Zeile|Zeilen) aufgrund von Datenfehlern nicht geladen.)|((Row|Rows) not loaded due to data errors.))

# the parameter to parse the log file generated by the xml data loader for looking up errors that should abort a job
LogParseError = load discontinued

# FilePattern fï¿½r die generierten Files (*.dat, *.ctl, *.log, *.bad, *.dis)
# Manuelle Anpassung muss mit der Entwicklung abgesprochen werden (die Dateien muessen in jedem Fall eindeutig sein.)
# Die Werte sind optional. DefaultWerte sind:
#LoaderFilePatternTableName=TT
#LoaderFilePatternPartitionId=PP
#LoaderFilePatternFileNumber=FF
#LoaderFilePatternFileName=FN
#LoaderFilePatternTimeMillis=SSSS
#LoaderFilePattern=TT_PP_FF_SSSS

# the following parameters of the xml data loader should not be changed
LoaderReadSize = 100000
LoaderBindSize = 100000
LoaderDirect = true
LoaderParallel = true
LoaderRows = 2000
LoaderMode = append
LoaderTerminated = \,
LoaderTableNameExtension = _tmp

# the maximum number of syntactically invalid data records that the SQL*Loader may allow per input csv file
# before it gives up reading the file
LoaderMaxError = 50

# specifies if an MPE job should abort when LoaderMaxError was exceeded (default true)
abortOnLoaderMaxError = true

# specifies if the folder containing the ctl and dat files should remain on the disk after
# the process finishes or fails. (default = false);
# LoaderKeepTempFiles=true

# specifies if an MPE job importing CSV files (e.g. mpeBase360X1CSV) should abort in the case that
# there is a mismatch between the count of records loaded from any csv file and the count of records expected from that file
# the expected record count X can be set inside every CSV file with "expected-number-of-records=X"
# any mismatch will be documented in x1csvloader.log, regardless of the value of this parameter
abortOnCSVExpectedRecordsMismatch = false

# the maximum number of pages within one generated pdf file (default = 100);
# when the mpe process (i.e. mpeLoanReports) which produces the pdf file reaches this page count
# the document counter (which is appended to the pdf filename) is incremented and another pdf file is produced
pagesPerPDF = 100
# size of the RecordBlock (number of rows put in it)
archive.recordBlock.size = 1000
# size of the blockBuffer (number of RecordBlock put in it)
archive.recordBlockBuffer.size = 100
# size of the stringBuffer (number of StringBlock put in it)
archive.stringBlockBuffer.size = 100
# number of consumers to prepare the strings that have to be written in a file
archive.stringProducersPerPeriod.maxActive = 5
# number of producers to launch at the same time
archive.blockProducersPerPeriod.maxActive = 5
# number of allowed parallel periodProducer program
archive.periodProducers.maxActive = 1
# sleep time when number of active periodProducer is more or equal to periodproducers parameter (in milliseconds)
archive.periodProducers.waitTime = 30000

# specfiy SQL hints for mpeMergerLoader(Additive Loading)
# default values:  rowMergerMasterMergeHintSelect = full(master) , rowMergerMasterMergeHintExists=hash_sj
#rowMergerMasterMergeHintSelect=full(master)
#rowMergerMasterMergeHintExists=hash_sj


# specify extra fields that should be anonymized, seperated by comma and/or space
# XMLAnonymizer.extraFieldsToBeAnonymized=

# Uncomment the following entry to switch off Oracle hints in a certain complex SELECT query in the step "DealToCollateral" within PrepareRMOE of the loan process.
# HINT_MODEL_DEALTOCOLLATERAL_DEACTIVATE=1

# Uncomment the following entry to replace the constant CONTRIBUTIONBOUNDARY in LPMatrixSolver class with a given value
# contributionBoundary = 1e-8

# Uncomment the following entry to replace the constant CONTRIBUTIONCOUNTER in LPMatrixSolver class with a given value
# contributionCounter = 1000

# Command to use for the SQL*Loader. Default sqlldr.
# databaseLoaderCommand=sqlldr

# Index usage can be monitored in the MPE processes. When set to true, index monitoring is activated in Oracle for indexes in temp schema.
# If an index is deleted, the information is stored in the table index_monitoring. Default value is false.
# indexMonitoring=false

# If collision checks are enabled for the XMLAnonymizer, the generation of a new anonymized value together with the collision check should
# be retried either until the collision check passes or until we have reached the maximum number of retries. Default value is false.
XMLAnonymizer.collisionChecks.enabled = false

# Represents the maximum number of retries in case the collision check is enabled. Default value is 3.
XMLAnonymizer.collisionChecks.maxRetries = 3
